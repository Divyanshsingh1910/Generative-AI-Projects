{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (1.24.3)\n",
      "Requirement already satisfied: tensorflow in ./.venv/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in ./.venv/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./.venv/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.56.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in ./.venv/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.venv/lib/python3.10/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in ./.venv/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in ./.venv/lib/python3.10/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib/python3.10/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in ./.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./.venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy\n",
    "! pip install tensorflow\n",
    "# ! pip install string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 00:51:39.237635: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-25 00:51:39.264220: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-25 00:51:39.265157: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-25 00:51:39.864327: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-25 00:51:40.460938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-25 00:51:40.461840: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Lambda, Conv1D\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
    "# Model architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=28, output_dim=32, input_length=30))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(LSTM(192))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.8,beta_2=0.6)\n",
    "model.compile(optimizer=optimizer, loss=root_mean_squared_error, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('HangmanMode.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = ['_','&'] + list(string.ascii_lowercase)\n",
    "char_to_int = {char: idx for idx, char in enumerate(all_characters)}\n",
    "\n",
    "int_to_char = {idx: char for char, idx in char_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(word):\n",
    "    word = list(word)\n",
    "    word = [[char for char in wd] for wd in word]\n",
    "    word_int = [[char_to_int[char] for char in word] for word in word]\n",
    "    word_padded = [array+[1]*(30-len(array)) for array in word_int]\n",
    "    return np.array(word_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtest = word2vec([\"elephant\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "y = model.predict(wordtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.argsort(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 26)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "t\n",
      "v\n",
      "o\n",
      "f\n",
      "m\n",
      "u\n",
      "e\n",
      "k\n",
      "d\n",
      "h\n",
      "l\n",
      "_\n",
      "b\n",
      "w\n",
      "s\n",
      "&\n",
      "c\n",
      "j\n",
      "i\n",
      "n\n",
      "g\n",
      "a\n",
      "r\n",
      "p\n",
      "q\n"
     ]
    }
   ],
   "source": [
    "for i in range(k.shape[1]):\n",
    "    print(int_to_char[k[0][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = (open(\"/home/divyansh/temp/Hangman Game/training_words.txt\",'r')).read()\n",
    "dict = dict.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vitaceous'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define your word dictionary with 2.5 lac words\n",
    "word_dictionary = dict\n",
    "\n",
    "# Hyperparameters\n",
    "EPISODES = 100\n",
    "MAX_ATTEMPTS = 6\n",
    "MAX_WORD_LENGTH = 20\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.9\n",
    "EPSILON = 0.2\n",
    "\n",
    "# Function to randomly sample a word for hangman\n",
    "def get_random_word():\n",
    "    return random.choice(word_dictionary)\n",
    "\n",
    "# Function to mask the word\n",
    "def mask_word(word, guessed_letters):\n",
    "    return \"\".join([c if c in guessed_letters else \"_\" for c in word])\n",
    "\n",
    "# Define the RL agent using Deep Q Networks (DQN)\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "        self.model = self.build_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(layers.Embedding(input_dim=26, output_dim=10, input_length=self.state_size))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(24, activation='relu'))\n",
    "        model.add(layers.Dense(24, activation='relu'))\n",
    "        model.add(layers.Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=self.optimizer)\n",
    "        return model\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= EPSILON:\n",
    "            return random.choice(range(self.action_size))\n",
    "        return np.argmax(self.model.predict(state)[0])\n",
    "\n",
    "    def train(self, state, action, reward, next_state, done):\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = (reward + GAMMA * np.amax(self.model.predict(next_state)[0]))\n",
    "        target_f = self.model.predict(state)\n",
    "        target_f[0][action] = target\n",
    "        self.model.fit(state, target_f, epochs=1, verbose=1)\n",
    "\n",
    "def play_hangman(agent):\n",
    "    action_size = 26\n",
    "\n",
    "    for episode in range(EPISODES):\n",
    "        word = get_random_word()\n",
    "        print(\"word is: \",word)\n",
    "        guessed_letters = set()\n",
    "        state = np.array([ord(c) - ord('a') for c in word])\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "\n",
    "        for attempt in range(MAX_ATTEMPTS):\n",
    "            action = agent.act(pad_sequences(state, maxlen=MAX_WORD_LENGTH, padding='post'))\n",
    "            guessed_letter = chr(action + ord('a'))\n",
    "            guessed_letters.add(guessed_letter)\n",
    "            \n",
    "            if guessed_letter in word:\n",
    "                reward = 1.0\n",
    "            else:\n",
    "                reward = -0.5\n",
    "            \n",
    "            next_word = mask_word(word, guessed_letters)\n",
    "            next_state = np.array([ord(c) - ord('a') for c in next_word])\n",
    "            next_state = np.expand_dims(next_state, axis=0)\n",
    "            next_state = pad_sequences(next_state, maxlen=MAX_WORD_LENGTH, padding='post')\n",
    "            \n",
    "            done = \"_\" not in next_word\n",
    "            agent.train(state, action, reward, next_state, done)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            print(f\"Episode: {episode}, Success rate: {evaluate(agent)}\")\n",
    "\n",
    "def evaluate(agent, num_trials=1000):\n",
    "    success_count = 0\n",
    "\n",
    "    for _ in range(num_trials):\n",
    "        word = get_random_word()\n",
    "        guessed_letters = set()\n",
    "\n",
    "        for _ in range(MAX_ATTEMPTS):\n",
    "            state = np.array([ord(c) - ord('a') for c in word])\n",
    "            state = np.expand_dims(state, axis=0)\n",
    "            state = pad_sequences(state, maxlen=MAX_WORD_LENGTH, padding='post')\n",
    "            \n",
    "            action = agent.act(state)\n",
    "            guessed_letter = chr(action + ord('a'))\n",
    "            guessed_letters.add(guessed_letter)\n",
    "\n",
    "            if guessed_letter in word:\n",
    "                break\n",
    "\n",
    "        if \"_\" not in mask_word(word, guessed_letters):\n",
    "            success_count += 1\n",
    "\n",
    "    return success_count / num_trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word is:  supawn\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/divyansh/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/divyansh/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/divyansh/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/divyansh/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"/home/divyansh/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/divyansh/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 30), found shape=(None, 20)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m action_size \u001b[39m=\u001b[39m \u001b[39m26\u001b[39m\n\u001b[1;32m      5\u001b[0m agent \u001b[39m=\u001b[39m DQNAgent(\u001b[39m30\u001b[39m, action_size)\n\u001b[0;32m----> 6\u001b[0m play_hangman(agent)\n",
      "Cell \u001b[0;32mIn[15], line 68\u001b[0m, in \u001b[0;36mplay_hangman\u001b[0;34m(agent)\u001b[0m\n\u001b[1;32m     65\u001b[0m state \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(state, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[39mfor\u001b[39;00m attempt \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(MAX_ATTEMPTS):\n\u001b[0;32m---> 68\u001b[0m     action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mact(pad_sequences(state, maxlen\u001b[39m=\u001b[39;49mMAX_WORD_LENGTH, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     69\u001b[0m     guessed_letter \u001b[39m=\u001b[39m \u001b[39mchr\u001b[39m(action \u001b[39m+\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     70\u001b[0m     guessed_letters\u001b[39m.\u001b[39madd(guessed_letter)\n",
      "Cell \u001b[0;32mIn[15], line 47\u001b[0m, in \u001b[0;36mDQNAgent.act\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m EPSILON:\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m random\u001b[39m.\u001b[39mchoice(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_size))\n\u001b[0;32m---> 47\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(state)[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filekor1ili2.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/divyansh/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/divyansh/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/divyansh/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/divyansh/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"/home/divyansh/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/divyansh/temp/Hangman Game/.venv/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 30), found shape=(None, 20)\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    action_size = 26\n",
    "\n",
    "    agent = DQNAgent(30, action_size)\n",
    "    play_hangman(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
